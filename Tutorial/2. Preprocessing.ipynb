{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56HM9qr_Oujd"
      },
      "source": [
        "### - NLP 전처리는 정해진 정답이 없으며 <strong>\"데이터\"</strong>와 <strong>\"목적\"</strong>에 따라 달라짐\r\n",
        "### - 모델의 입력인 단어, 문장, 문서의 vector를 만들기 전에 진행됨\r\n",
        "\r\n",
        "#### <순서>\r\n",
        "\r\n",
        "1. 데이터를 불러온 후 각 신문기사들을 눈으로 확인하며 특수문자, 불용어 그리고 문장 구조에 대한 감을 잡습니다.\r\n",
        "2. 문제의 목적과 분석자의 재량에 따라 불용어를 설정하고 리스트에 저장합니다. 이번 대회에서는 <strong>\"특수 문자\"</strong>와 <strong>\"조사\"</strong>만 제거해도 어느 정도 높은 정확도를 얻을 수 있습니다.\r\n",
        "3. 불용어 이외의 특수 문자들을 제거합니다. 이번 대회를 위해 저는 <u>정규표현식 패키지(re)</u>를 사용하여 <strong>\"한글과 영어 소문자를 제외한 모든 글자들을 제거\"</strong>하였습니다.\r\n",
        "4. 형태소 분석을 통해 문장을 형태소 단위의 토큰으로 분리합니다. 이때 내가 설정한 불용어들을 결과로 반환해주는 형태소 분석기를 사용하셔야 합니다. 예를 들어 조사를 불용어로 설정하였는데 조사를 분리해주지 못하는 형태소 분석기는 후보에서 제외하시면 됩니다.\r\n",
        "5. 형태소 단위의 토큰들을 기반으로 리스트에 저장된 불용어를 제거합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpcBjU1pO5ZD"
      },
      "source": [
        "### 1. 형태소 분석(Stemming)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7atlzNhP8qw"
      },
      "source": [
        "- **형태소 분석** : 단어나 문장의 언어적 속성을 파악하는 것. 보통 품사의 태깅(PoS)을 통해 이루어지며 Konlpy 패키지에 있는 다양한 함수를 이용하여 진행 가능.\r\n",
        "- **형태소 분석을 하는 이유** : 주로 **형태소 단위로 의미있는 단어**를 가져가고 싶거나 품사 태깅을 통해 **형용사나 명사를 추출**하고 싶을 때 많이 이용.\r\n",
        "- 문장을 띄어쓰기 단위로만 분류하여 vectorization을 하게 되면, \"데이콘이\", \"데이콘은\", \"데이콘을\"과 같이 \"데이콘\"이라는 같은 의미의 토큰 세개가 **서로 다른 vector를 갖게 됨**. 하지만 **형태소 분석**을 통해 \"데이콘\"이라는 **토큰을 추출한다면 세 단어는 동일한 vector를 갖게되며 <u>모델이 해당 토큰을 더 잘 학습</u>하는 데 도움이 됨.**\r\n",
        "- ***형태소 분석은 모델링보다 성능에 더 중요한 영향을 미치는 아주 중요한 과정!!***. 따라서 다양한 형태소 분석기를 사용하여 결과를 비교하는 게 좋음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgUoTGLmOEnH",
        "outputId": "8c895438-a9b3-4121-cfca-d88917687c45"
      },
      "source": [
        "! pip install konlpy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.4MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.3MB/s \n",
            "\u001b[?25hCollecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/21/9e2c0dbf9df856e6392a1aec1d18006c60b175aa4e31d351e8278a8a63c0/JPype1-1.2.0-cp36-cp36m-manylinux2010_x86_64.whl (453kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 49.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.4)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: beautifulsoup4, tweepy, JPype1, colorama, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-1.2.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Sybt_yr5OpjJ",
        "outputId": "8c8b84d2-9e86-49f4-9be7-501220ef3c7e"
      },
      "source": [
        "import konlpy\r\n",
        "konlpy.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.5.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7VBSJ-q1yAL"
      },
      "source": [
        "1-1. Kkma()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZoHoHtQNheo",
        "outputId": "688ce25e-b677-4194-f429-cb9ec26a9219"
      },
      "source": [
        "# 11.542초\r\n",
        "from konlpy.tag import Kkma\r\n",
        "kkma = Kkma()\r\n",
        "\r\n",
        "sentence = '데이콘에서 다양한 컴피티션을 즐기면서 실력있는 데이터 분석가로 성장하세요!!.'\r\n",
        "\r\n",
        "print(\"형태소 단위로 문장 분리\")\r\n",
        "print(\"----------------------\")\r\n",
        "print(kkma.morphs(sentence))\r\n",
        "print(\" \")\r\n",
        "print(\"문장에서 명사 추출\")\r\n",
        "print(\"----------------------\")\r\n",
        "print(kkma.nouns(sentence))\r\n",
        "print(\" \")\r\n",
        "print(\"품사 태깅(PoS)\")\r\n",
        "print(\"----------------------\")\r\n",
        "print(kkma.pos(sentence))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "형태소 단위로 문장 분리\n",
            "----------------------\n",
            "['데이', '콘', '에서', '다양', '하', 'ㄴ', '컴피티션', '을', '즐기', '면서', '실력', '있', '는', '데이터', '분석가', '로', '성장', '하', '세요', '!!', '.']\n",
            " \n",
            "문장에서 명사 추출\n",
            "----------------------\n",
            "['데이', '데이콘', '콘', '다양', '컴피티션', '실력', '데이터', '분석가', '성장']\n",
            " \n",
            "품사 태깅(PoS)\n",
            "----------------------\n",
            "[('데이', 'NNG'), ('콘', 'NNG'), ('에서', 'JKM'), ('다양', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('컴피티션', 'UN'), ('을', 'JKO'), ('즐기', 'VV'), ('면서', 'ECE'), ('실력', 'NNG'), ('있', 'VV'), ('는', 'ETD'), ('데이터', 'NNG'), ('분석가', 'NNG'), ('로', 'JKM'), ('성장', 'NNG'), ('하', 'XSV'), ('세요', 'EFN'), ('!!', 'SW'), ('.', 'SF')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlODpz7s12e9"
      },
      "source": [
        "1-2. Okt()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjZxYdf5Nmlj",
        "outputId": "6bc530d6-33cf-4085-9b16-880e9c0db6e6"
      },
      "source": [
        "# 9.816초\r\n",
        "from konlpy.tag import Okt\r\n",
        "Okt = Okt()\r\n",
        "\r\n",
        "sentence = '데이콘에서 다양한 컴피티션을 즐기면서 실력있는 데이터 분석가로 성장하세요!!.'\r\n",
        "\r\n",
        "print(\"형태소 단위로 문장 분리\")\r\n",
        "print(\"----------------------\")\r\n",
        "print(Okt.morphs(sentence))\r\n",
        "print(\" \")\r\n",
        "print(\"문장에서 명사 추출\")\r\n",
        "print(\"----------------------\")\r\n",
        "print(Okt.nouns(sentence))\r\n",
        "print(\" \")\r\n",
        "print(\"품사 태깅(PoS)\")\r\n",
        "print(\"----------------------\")\r\n",
        "print(Okt.pos(sentence))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "형태소 단위로 문장 분리\n",
            "----------------------\n",
            "['데', '이콘', '에서', '다양한', '컴피티션', '을', '즐기면서', '실력', '있는', '데이터', '분석', '가로', '성장하세요', '!!.']\n",
            " \n",
            "문장에서 명사 추출\n",
            "----------------------\n",
            "['데', '이콘', '컴피티션', '실력', '데이터', '분석', '가로']\n",
            " \n",
            "품사 태깅(PoS)\n",
            "----------------------\n",
            "[('데', 'Noun'), ('이콘', 'Noun'), ('에서', 'Josa'), ('다양한', 'Adjective'), ('컴피티션', 'Noun'), ('을', 'Josa'), ('즐기면서', 'Verb'), ('실력', 'Noun'), ('있는', 'Adjective'), ('데이터', 'Noun'), ('분석', 'Noun'), ('가로', 'Noun'), ('성장하세요', 'Adjective'), ('!!.', 'Punctuation')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_7bY_fd44PU"
      },
      "source": [
        "**<형태소 분석기 성능 비교>**\r\n",
        "- Mecab: 굉장히 속도가 빠르면서도 좋은 분석 결과를 보여준다.\r\n",
        "- Komoran: 댓글과 같이 정제되지 않은 글에 대해서 먼저 사용해보면 좋다.(오탈자를 어느정도 고려해준다.)\r\n",
        "- Kkma: 분석 시간이 오래걸리기 때문에 잘 이용하지 않게 된다.\r\n",
        "- Okt: 품사 태깅 결과를 Noun, Verb등 알아보기 쉽게 반환해준다.\r\n",
        "- khaiii: 카카오에서 가장 최근에 공개한 분석기, 성능이 좋다고 알려져 있으며 다양한 실험이 필요하다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf9WTyGY5DBO"
      },
      "source": [
        "### 2. 표제어 추출(Lemmatization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t17wn_P05Nob"
      },
      "source": [
        "Lemmatization과 Stemming은 큰 차이가 없음. 단어의 본 모습을 찾아주는 과정으로서 형태소 분석기들을 이용하면 어느 정도 \"어간 추출\"이 가능. 따라서 형태소 분석(Pos Tagging)을 stemming이라고 표기한 것."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PX9PvJK2K7h",
        "outputId": "9cb38347-fa54-41bc-fc96-7044ce9e3209"
      },
      "source": [
        "from konlpy.tag import Kkma\r\n",
        "kkma = Kkma()\r\n",
        "\r\n",
        "sentence = '성장했었다.'\r\n",
        "\r\n",
        "print(\"품사 태깅(PoS)\")\r\n",
        "print(\"----------------------\")\r\n",
        "print(kkma.pos(sentence))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "품사 태깅(PoS)\n",
            "----------------------\n",
            "[('성장', 'NNG'), ('하', 'XSV'), ('었', 'EPT'), ('었', 'EPT'), ('다', 'EFN'), ('.', 'SF')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD8DVHUg5nhZ",
        "outputId": "b0180a05-2b10-44c0-b14f-8c2fbb70df59"
      },
      "source": [
        "sentence = '성장하였었다.'\r\n",
        "\r\n",
        "print(\"품사 태깅(PoS)\")\r\n",
        "print(\"----------------------\")\r\n",
        "print(kkma.pos(sentence))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "품사 태깅(PoS)\n",
            "----------------------\n",
            "[('성장', 'NNG'), ('하', 'XSV'), ('였', 'EPT'), ('었', 'EPT'), ('다', 'EFN'), ('.', 'SF')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya7Ax9tI51mT"
      },
      "source": [
        "### 3. 불용어 제거(Stopwords removing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U06uPeQL6vZk"
      },
      "source": [
        "- 불용어 : 문장에서 큰 의미가 없다고 생각되는 단어, 글자들\r\n",
        "- 불용어는 데이터와 문제에 따라 유동적임.\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "예시 : \"이번에 새롭게 개봉한 영화의 배우들은 모두 훌륭한 연기력과 아름다운 목소리를 갖고 있어!!\"\r\n",
        "- 예시 문장을 감성분석하게 되면 **\"훌륭한\"**과 **\"아름다운\"**이 주요 특징으로 사용되겠지만, 경우에 따라서는 형용사들을 제외한 **배우들의 연기력과 목소리**라는 정보에 집중해야 함. 이럴 때는 **\"훌륭한\"**과 **\"아름다운\"**은 불용어로 정의됨.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7bMkIuR5t1a"
      },
      "source": [
        "# 1. 영어 소문자와 한글을 제외한 모든 문자를 제거\r\n",
        "# 2. Okt를 이용해 형태소 분석\r\n",
        "# 3. 형태소 분석기를 거쳐 나온 결과들 중 stopwords 리스트에 포함되지 않는 토큰만  token이라는 리스트에 반환\r\n",
        "\r\n",
        "import re\r\n",
        "from konlpy.tag import Okt\r\n",
        "tokenizer = Okt()\r\n",
        "\r\n",
        "def text_preprocessing(text, tokenizer):\r\n",
        "  stopwords = ['을', '를', '이', '가', '은', '는']\r\n",
        "\r\n",
        "  txt = re.sub('[^가-힣a-z]', ' ', text)   \r\n",
        "  token = tokenizer.morphs(txt)\r\n",
        "  token = [t for t in token if t not in stopwords]\r\n",
        "\r\n",
        "  return token\r\n",
        "\r\n",
        "ex_text = \"이번에 새롭게 개봉한 영화의 배우들은 모두 훌륭한 연기력과 아름다운 목소리를 갖고 있어!!\"\r\n",
        "example_pre = text_preprocessing(ex_text, tokenizer)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsQbhktM9zEy",
        "outputId": "d6e0b01b-7928-4553-a61a-2c431194122b"
      },
      "source": [
        "print(example_pre)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['이번', '에', '새롭게', '개봉', '한', '영화', '의', '배우', '들', '모두', '훌륭한', '연기력', '과', '아름다운', '목소리', '갖고', '있어']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2saRh4hb93G7"
      },
      "source": [
        "### 4. 대회 적용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EfXBuRL0__oB",
        "outputId": "a745ca4c-1420-42a9-9b9e-e0a171d1baf7"
      },
      "source": [
        "import os\r\n",
        "os.getcwd()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIMvVIAhADNj"
      },
      "source": [
        "os.chdir('drive/MyDrive/NLP/Dacon_NH competition/data')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mWW4ESt95X-"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "train = pd.read_csv('news_train.csv')\r\n",
        "\r\n",
        "def text_preprocessing(text_list):\r\n",
        "  stopwords = ['을', '를', '이', '가', '은', '는', 'null']   # 불용어 설정\r\n",
        "  tokenizer = Okt()   # 형태소 분석기\r\n",
        "  token_list = []\r\n",
        "\r\n",
        "  for text in text_list:\r\n",
        "    txt = re.sub('[^가-힣a-z]', ' ', text)   # 한글과 영어 소문자만 남기고 다른 글자 모두 제거\r\n",
        "    token = tokenizer.morphs(txt)            # 형태소 분석\r\n",
        "    token = [t for t in token if t not in stopwords or type(t) != float]   # 형태소 분석 결과 중 stopwords에 해당하지 않는 것만 추출\r\n",
        "    token_list.append(token)\r\n",
        "\r\n",
        "  return token_list, tokenizer\r\n",
        "\r\n",
        "# 형태소 분석기를 따로 저장한 이유는 후에 test 데이터 전처리를 진행할 때 이용해야 되기 때문\r\n",
        "train['new_article'], okt = text_preprocessing(train['content'])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        },
        "id": "WrZ1nyxCAY3x",
        "outputId": "c8f183e3-d00e-4b39-d521-5ee86a87a66b"
      },
      "source": [
        "train.head(20)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_id</th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>content</th>\n",
              "      <th>ord</th>\n",
              "      <th>info</th>\n",
              "      <th>new_article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NEWS02580</td>\n",
              "      <td>20200605</td>\n",
              "      <td>[마감]코스닥 기관 678억 순매도</td>\n",
              "      <td>[이데일리 MARKETPOINT]15:32 현재 코스닥 기관 678억 순매도</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[이데일리, 현재, 코스닥, 기관, 억, 순, 매도]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NEWS02580</td>\n",
              "      <td>20200605</td>\n",
              "      <td>[마감]코스닥 기관 678억 순매도</td>\n",
              "      <td>\"실적기반\" 저가에 매집해야 할 8월 급등유망주 TOP 5 전격공개</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>[실적, 기반, 저가, 에, 매집, 해야, 할, 월, 급등, 유망, 주, 전격, 공개]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NEWS02580</td>\n",
              "      <td>20200605</td>\n",
              "      <td>[마감]코스닥 기관 678억 순매도</td>\n",
              "      <td>하이스탁론, 선취수수료 없는 월 0.4% 최저금리 상품 출시</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>[하, 이스, 탁론, 선취, 수수료, 없는, 월, 최저, 금리, 상품, 출시]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NEWS02580</td>\n",
              "      <td>20200605</td>\n",
              "      <td>[마감]코스닥 기관 678억 순매도</td>\n",
              "      <td>종합 경제정보 미디어 이데일리 - 무단전재 &amp; 재배포 금지</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>[종합, 경제, 정보, 미디어, 이데일리, 무단, 전, 재, 재, 배포, 금지]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NEWS09727</td>\n",
              "      <td>20200626</td>\n",
              "      <td>롯데·공영 등 7개 TV 홈쇼핑들, 동행세일 동참</td>\n",
              "      <td>전국적인 소비 붐 조성에 기여할 예정</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[전국, 적, 인, 소비, 붐, 조성, 에, 기여, 할, 예정]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NEWS09727</td>\n",
              "      <td>20200626</td>\n",
              "      <td>롯데·공영 등 7개 TV 홈쇼핑들, 동행세일 동참</td>\n",
              "      <td>[이데일리 권오석 기자] 중소벤처기업부(이하 중기부)는 대한민국 동행세일에 7개 T...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>[이데일리, 권오석, 기자, 중소, 벤처기업, 부, 이하, 중, 기부, 는, 대한민...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NEWS09727</td>\n",
              "      <td>20200626</td>\n",
              "      <td>롯데·공영 등 7개 TV 홈쇼핑들, 동행세일 동참</td>\n",
              "      <td>대한민국 동행세일은 라이브 커머스, 언택트 콘서트, O2O 행사 연계 등 비대면이라...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>[대한민국, 동행, 세, 일, 은, 라이브, 커머스, 언택트, 콘서트, 행사, 연,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NEWS09727</td>\n",
              "      <td>20200626</td>\n",
              "      <td>롯데·공영 등 7개 TV 홈쇼핑들, 동행세일 동참</td>\n",
              "      <td>6개 권역에서의 현장행사와 온·오프라인 판촉, TV홈쇼핑 등 연계행사를 통해 소비심...</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>[개, 권역, 에서의, 현장, 행사, 와, 온, 오프라인, 판촉, 홈쇼핑, 등, 연...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NEWS09727</td>\n",
              "      <td>20200626</td>\n",
              "      <td>롯데·공영 등 7개 TV 홈쇼핑들, 동행세일 동참</td>\n",
              "      <td>이번 동행세일에서는 롯데·공영·CJ·현대·GS·NS·홈앤쇼핑 등 7개 TV 홈쇼핑사...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>[이번, 동행, 세, 일, 에서는, 롯데, 공영, 현대, 홈앤쇼핑, 등, 개, 홈쇼...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NEWS09727</td>\n",
              "      <td>20200626</td>\n",
              "      <td>롯데·공영 등 7개 TV 홈쇼핑들, 동행세일 동참</td>\n",
              "      <td>동행세일 기간 중 홈쇼핑사에서는 판매방송 사이에 영상을 노출하는 방식(SB, sta...</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>[동행, 세, 일, 기간, 중, 홈쇼핑, 사, 에서는, 판매, 방송, 사이, 에, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NEWS09727</td>\n",
              "      <td>20200626</td>\n",
              "      <td>롯데·공영 등 7개 TV 홈쇼핑들, 동행세일 동참</td>\n",
              "      <td>첫 방송으로 6월 26일부터 공영홈쇼핑은 마스크, 식기세트 등 생활용품과 신선식품 ...</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>[첫, 방송, 으로, 월, 일, 부터, 공, 영, 홈쇼핑, 은, 마스크, 식기, 세...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>NEWS09727</td>\n",
              "      <td>20200626</td>\n",
              "      <td>롯데·공영 등 7개 TV 홈쇼핑들, 동행세일 동참</td>\n",
              "      <td>특히 롯데홈쇼핑은 6월 26일 부산 벡스코에서 현장 이원 생방송을 통해 동행세일 현...</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>[특히, 롯데, 홈쇼핑, 은, 월, 일, 부산, 벡스코, 에서, 현장, 이원, 생방...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>NEWS09727</td>\n",
              "      <td>20200626</td>\n",
              "      <td>롯데·공영 등 7개 TV 홈쇼핑들, 동행세일 동참</td>\n",
              "      <td>박영선 중기부 장관이 쇼호스트로 깜짝 등장해 동행세일을 마련한 취지와 대한민국 중소...</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>[박영선, 중, 기부, 장관, 이, 쇼호, 스트로, 깜짝, 등장, 해, 동행, 세,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>NEWS09727</td>\n",
              "      <td>20200626</td>\n",
              "      <td>롯데·공영 등 7개 TV 홈쇼핑들, 동행세일 동참</td>\n",
              "      <td>현장 이원 생방송의 다음 주자로는, 공영홈쇼핑이 7월 10일부터 12일까지 서울 코...</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>[현장, 이원, 생방송, 의, 다음, 주자, 로는, 공, 영, 홈쇼핑, 이, 월, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NEWS09727</td>\n",
              "      <td>20200626</td>\n",
              "      <td>롯데·공영 등 7개 TV 홈쇼핑들, 동행세일 동참</td>\n",
              "      <td>박영선 장관은 이번 동행세일 행사에 TV홈쇼핑사의 동참을 통해 내수 활성화에 한발짝...</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>[박영선, 장관, 은, 이번, 동행, 세, 일, 행사, 에, 홈쇼핑, 사의, 동참,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NEWS09727</td>\n",
              "      <td>20200626</td>\n",
              "      <td>롯데·공영 등 7개 TV 홈쇼핑들, 동행세일 동참</td>\n",
              "      <td>한편 앞서 중기부에 따르면 지난 25일 글로벌 쇼트 비디오 앱 틱톡(Tiktok)의...</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>[한편, 앞서, 중, 기부, 에, 따르면, 지난, 일, 글로벌, 쇼트, 비디오, 앱...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>NEWS09727</td>\n",
              "      <td>20200626</td>\n",
              "      <td>롯데·공영 등 7개 TV 홈쇼핑들, 동행세일 동참</td>\n",
              "      <td>\"실적기반\" 저가에 매집해야 할 8월 급등유망주 TOP 5 전격공개</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>[실적, 기반, 저가, 에, 매집, 해야, 할, 월, 급등, 유망, 주, 전격, 공개]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>NEWS09727</td>\n",
              "      <td>20200626</td>\n",
              "      <td>롯데·공영 등 7개 TV 홈쇼핑들, 동행세일 동참</td>\n",
              "      <td>하이스탁론, 선취수수료 없는 월 0.4% 최저금리 상품 출시</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>[하, 이스, 탁론, 선취, 수수료, 없는, 월, 최저, 금리, 상품, 출시]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>NEWS09727</td>\n",
              "      <td>20200626</td>\n",
              "      <td>롯데·공영 등 7개 TV 홈쇼핑들, 동행세일 동참</td>\n",
              "      <td>종합 경제정보 미디어 이데일리 - 무단전재 &amp; 재배포 금지</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>[종합, 경제, 정보, 미디어, 이데일리, 무단, 전, 재, 재, 배포, 금지]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>NEWS07691</td>\n",
              "      <td>20200518</td>\n",
              "      <td>13년만에 늦깎이 개발 '양주 회천' 봄볕 드나</td>\n",
              "      <td>GTX-C노선 내년 착공 확정- 지구 내 1호선 회정역 2023년 신설- 옥정 비해...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[노선, 내년, 착공, 확정, 지구, 내, 호선, 회정, 역, 년, 신설, 옥정, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         n_id  ...                                        new_article\n",
              "0   NEWS02580  ...                      [이데일리, 현재, 코스닥, 기관, 억, 순, 매도]\n",
              "1   NEWS02580  ...   [실적, 기반, 저가, 에, 매집, 해야, 할, 월, 급등, 유망, 주, 전격, 공개]\n",
              "2   NEWS02580  ...        [하, 이스, 탁론, 선취, 수수료, 없는, 월, 최저, 금리, 상품, 출시]\n",
              "3   NEWS02580  ...       [종합, 경제, 정보, 미디어, 이데일리, 무단, 전, 재, 재, 배포, 금지]\n",
              "4   NEWS09727  ...                [전국, 적, 인, 소비, 붐, 조성, 에, 기여, 할, 예정]\n",
              "5   NEWS09727  ...  [이데일리, 권오석, 기자, 중소, 벤처기업, 부, 이하, 중, 기부, 는, 대한민...\n",
              "6   NEWS09727  ...  [대한민국, 동행, 세, 일, 은, 라이브, 커머스, 언택트, 콘서트, 행사, 연,...\n",
              "7   NEWS09727  ...  [개, 권역, 에서의, 현장, 행사, 와, 온, 오프라인, 판촉, 홈쇼핑, 등, 연...\n",
              "8   NEWS09727  ...  [이번, 동행, 세, 일, 에서는, 롯데, 공영, 현대, 홈앤쇼핑, 등, 개, 홈쇼...\n",
              "9   NEWS09727  ...  [동행, 세, 일, 기간, 중, 홈쇼핑, 사, 에서는, 판매, 방송, 사이, 에, ...\n",
              "10  NEWS09727  ...  [첫, 방송, 으로, 월, 일, 부터, 공, 영, 홈쇼핑, 은, 마스크, 식기, 세...\n",
              "11  NEWS09727  ...  [특히, 롯데, 홈쇼핑, 은, 월, 일, 부산, 벡스코, 에서, 현장, 이원, 생방...\n",
              "12  NEWS09727  ...  [박영선, 중, 기부, 장관, 이, 쇼호, 스트로, 깜짝, 등장, 해, 동행, 세,...\n",
              "13  NEWS09727  ...  [현장, 이원, 생방송, 의, 다음, 주자, 로는, 공, 영, 홈쇼핑, 이, 월, ...\n",
              "14  NEWS09727  ...  [박영선, 장관, 은, 이번, 동행, 세, 일, 행사, 에, 홈쇼핑, 사의, 동참,...\n",
              "15  NEWS09727  ...  [한편, 앞서, 중, 기부, 에, 따르면, 지난, 일, 글로벌, 쇼트, 비디오, 앱...\n",
              "16  NEWS09727  ...   [실적, 기반, 저가, 에, 매집, 해야, 할, 월, 급등, 유망, 주, 전격, 공개]\n",
              "17  NEWS09727  ...        [하, 이스, 탁론, 선취, 수수료, 없는, 월, 최저, 금리, 상품, 출시]\n",
              "18  NEWS09727  ...       [종합, 경제, 정보, 미디어, 이데일리, 무단, 전, 재, 재, 배포, 금지]\n",
              "19  NEWS07691  ...  [노선, 내년, 착공, 확정, 지구, 내, 호선, 회정, 역, 년, 신설, 옥정, ...\n",
              "\n",
              "[20 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOZZtEixDlMl"
      },
      "source": [
        "train.to_csv('news_train_preprocessing.csv')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiZq7ZpsEGwO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}